{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee959aa-17aa-4878-a4bd-acfe0402648e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import quantlaw.utils.networkx\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lxml\n",
    "import json\n",
    "import copy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353ede0f-78f3-4d61-98e9-76aa1ddb5be0",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "- Take a crossref graph (in which crossreferences are modeled at the lowest possible level at source and target. If a detailed citekey cannot be resolved the last component of the citekey is removed and we try to resolve the broader reference. E.g. if `26_7604_h_3` cannot be found we try to match to `26_7604_h` and then to `26_7604` )\n",
    "- Remove all containment edges which targets are not subseqitems. -> Edges in the remaining graph represent the hierarchy between seqitems and subseqitems (and the cross-references.) (We don't need higher containment edges to follow cross-references.)\n",
    "- Remove all nodes larger than 1000 tokens. This way we ignore overbroad references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928de15-1731-40df-b1a8-c0e8c9488cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subseqitem_mapping(hierarchy_g):\n",
    "    '''\n",
    "    Create a mapping from subseqitem to their parent seqitem. \n",
    "    The mapping also includes a mapping from a seqitem to itself.\n",
    "    '''\n",
    "    subseqitems2seqitems = {}\n",
    "    for n, node_type in sorted(hierarchy_g.nodes(data='type')):\n",
    "        if node_type == 'seqitem':\n",
    "            subseqitems2seqitems[n] = n\n",
    "            for descendant in nx.descendants(hierarchy_g, n):\n",
    "                subseqitems2seqitems[descendant] = n\n",
    "    return subseqitems2seqitems\n",
    "\n",
    "def filtered_graph(g, token_threshold):\n",
    "    '''\n",
    "    Remove containment edges above seqitem level \n",
    "    and larger that the `token_threshold`.\n",
    "    \n",
    "    '''\n",
    "    node_types = nx.get_node_attributes(g, 'type')\n",
    "    g.remove_edges_from([\n",
    "        (u, v, k)\n",
    "        for u, v, k, edge_type in g.edges(keys = True, data='edge_type')\n",
    "        if not (\n",
    "            node_types[v] == 'subseqitem' or \n",
    "            edge_type =='reference'\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    g.remove_nodes_from([\n",
    "        n\n",
    "        for n, tokens_n in g.nodes(data='tokens_n')\n",
    "        if tokens_n and tokens_n > token_threshold\n",
    "    ])\n",
    "    \n",
    "    nx.set_edge_attributes(g, {\n",
    "        (u, v , k): 1 if edge_type == 'reference' else 0\n",
    "        for u, v , k, edge_type in g.edges(keys=True, data='edge_type')\n",
    "    }, 'dist_weight')\n",
    "\n",
    "    \n",
    "def direct_path_graph(g):\n",
    "    '''\n",
    "    Create a new graph with the same nodes as g and for\n",
    "    each reference edge in g add edges from its source the the target and \n",
    "    all nodes contained in the target.\n",
    "    Do not add containment edged.\n",
    "    Remove self-loops.\n",
    "    '''\n",
    "    h = nx.DiGraph()\n",
    "    \n",
    "    direct_edges = [\n",
    "        (u, v) \n",
    "        for u, v, edge_type in g.edges(data='edge_type') \n",
    "        if edge_type == 'reference'\n",
    "    ]\n",
    "    direct_edges = [\n",
    "        (u, v, {'edge_key': i})\n",
    "        for i, (u, v) in enumerate(direct_edges)\n",
    "    ]\n",
    "\n",
    "    h.add_edges_from(direct_edges)\n",
    "    for u, v, edge_type in sorted(\n",
    "        g.edges(data='edge_type'), \n",
    "        key=lambda e: e[0]\n",
    "    ):\n",
    "        if edge_type == 'containment':\n",
    "            for citing_node, _, edge_key in h.in_edges(u, data='edge_key'):\n",
    "                h.add_edge(citing_node, v, edge_key=edge_key)\n",
    "    \n",
    "    tokens_n = nx.get_node_attributes(g, 'tokens_n')\n",
    "    nx.set_node_attributes(h, {n: tokens_n[n] for n in h.nodes}, 'tokens_n')\n",
    "\n",
    "    h.remove_edges_from([(u, v) for u, v in h.edges() if u == v])\n",
    "    return h\n",
    "\n",
    "def remove_contained_nodes(nodes, descendants_cache, contained_edges):\n",
    "    '''\n",
    "    Gives a set of nodes (`nodes`). Gerenate a subset that does not a contain a node of the\n",
    "    given set if an ancestors (in the hierarchy) of this node is also part of the set.\n",
    "    '''\n",
    "    contained_nodes = set()\n",
    "    for node in nodes:\n",
    "        contained_nodes.update(get_descendants(node, descendants_cache, contained_edges))\n",
    "    return nodes - contained_nodes\n",
    "\n",
    "\n",
    "def get_containment_edges(g):\n",
    "    '''\n",
    "    Create a dict mapping a node to a set of its direct children in the hierarchy graph.\n",
    "    '''\n",
    "    contained_edges = dict()\n",
    "    for u, v, edge_type in g.edges(data='edge_type'):\n",
    "        if edge_type == 'containment':\n",
    "            if u in contained_edges:\n",
    "                contained_edges[u].add(v)\n",
    "            else:\n",
    "                contained_edges[u] = {v}\n",
    "    return contained_edges\n",
    "\n",
    "\n",
    "def get_descendants(node, descendants_cache, contained_edges):\n",
    "    '''\n",
    "    Get all descendants for node. Using an contained_edges dict and descendants_cache dict \n",
    "    makes this function efficient when using get_descendants multiple times. \n",
    "    '''\n",
    "    if node not in descendants_cache:\n",
    "        descendants = set()\n",
    "        if node in contained_edges:  # Node has children\n",
    "            for child in contained_edges[node]:\n",
    "                descendants.add(child)\n",
    "                descendants.update(get_descendants(child, descendants_cache, contained_edges))\n",
    "        descendants_cache[node] = descendants\n",
    "    return descendants_cache[node]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d022bb4-5c0d-4184-9845-43c9173a3e9c",
   "metadata": {},
   "source": [
    "# Overlapping sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add5ce57-c736-46ea-a03c-4ef99477ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stats(\n",
    "    nodes_without_contained, ref_edges, descendants_cache, contained_edges, subseqitems2seqitems, g_tokens_n\n",
    "):\n",
    "    nodes_len = len(nodes_without_contained)\n",
    "    \n",
    "    seqitems = {subseqitems2seqitems[n] for n in nodes_without_contained}\n",
    "    seqitems_len = len(seqitems)\n",
    "\n",
    "    titles = {n.split('_')[0] for n in nodes_without_contained}\n",
    "    title_len = len(titles)\n",
    "    \n",
    "    ref_edges_len = len(ref_edges)\n",
    "    \n",
    "    tokens_n = int(sum(g_tokens_n[n] for n in nodes_without_contained))\n",
    "    \n",
    "    return dict(\n",
    "        root=n,\n",
    "        year=year,\n",
    "        nodes=nodes_len,\n",
    "        ref_edges=ref_edges_len,\n",
    "        seqitems=seqitems_len,\n",
    "        titles=title_len,\n",
    "        tokens_n=tokens_n\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0157598e-fe1c-4384-9fef-997a34753bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for year in range(1998, 2020):\n",
    "    year = str(year)\n",
    "    \n",
    "    g = quantlaw.utils.networkx.load_graph_from_csv_files(\n",
    "        '../../legal-networks-data/us/4_crossreference_graph/detailed/',\n",
    "        year,\n",
    "        filter=None\n",
    "    )\n",
    "    subseqitems2seqitems = subseqitem_mapping(quantlaw.utils.networkx.hierarchy_graph(g))\n",
    "\n",
    "    filtered_graph(g, token_threshold=1000)\n",
    "    h = quantlaw.utils.networkx.hierarchy_graph(g)\n",
    "    h.remove_node('root')\n",
    "    descendants_cache = {}\n",
    "    contained_edges = get_containment_edges(g)\n",
    "    g = direct_path_graph(g)\n",
    "\n",
    "    root_nodes = {n for n, degree in h.in_degree() if degree == 0}\n",
    "    \n",
    "    base_nodes = remove_contained_nodes(\n",
    "        g.nodes, descendants_cache, contained_edges\n",
    "    )\n",
    "    \n",
    "    edge_key_dict = defaultdict(dict)\n",
    "    for (u, v), k in nx.get_edge_attributes(g, 'edge_key').items():\n",
    "        edge_key_dict[u][v] = k\n",
    "    edge_key_dict = dict(edge_key_dict)\n",
    "\n",
    "    for radius in [\n",
    "        None, \n",
    "#         3, \n",
    "#         6\n",
    "    ]:\n",
    "        g_tokens_n = nx.get_node_attributes(g, 'tokens_n')\n",
    "        data = []\n",
    "        for i, n in enumerate(base_nodes):\n",
    "            \n",
    "            shortest_path_dict = nx.shortest_path(g, n)\n",
    "            \n",
    "            reachable_nodes_and_self = {\n",
    "                path_root \n",
    "                for path_root, path in shortest_path_dict.items()\n",
    "                if not radius or len(path) <= radius + 1\n",
    "            } | {n}\n",
    "            \n",
    "            nodes_without_contained = remove_contained_nodes(\n",
    "                reachable_nodes_and_self, descendants_cache, contained_edges\n",
    "            ) \n",
    "            \n",
    "            ref_edges = {\n",
    "                k\n",
    "                for u in reachable_nodes_and_self\n",
    "                for v, k in edge_key_dict.get(u, {}).items()\n",
    "                if v in reachable_nodes_and_self\n",
    "            }\n",
    "            \n",
    "            if nodes_without_contained:\n",
    "                n_data = generate_stats(\n",
    "                    nodes_without_contained, ref_edges, descendants_cache, contained_edges, \n",
    "                    subseqitems2seqitems, g_tokens_n\n",
    "                )\n",
    "                data.append(n_data)\n",
    "        df = pd.DataFrame(data).sort_values('root')\n",
    "        df.to_csv(\n",
    "            f'../data/reference_sets_{year}_radius_{radius}.csv'\n",
    "            if radius else\n",
    "            f'../data/reference_sets_{year}.csv'\n",
    "        )\n",
    "    \n",
    "    print('Done', year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
